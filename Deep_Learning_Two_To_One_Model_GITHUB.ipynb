{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, datetime\n",
    "\n",
    "import soundfile\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script is to create and train two neural networks models that converge into one full model.\n",
    "\n",
    "The first model is to intake the vocal profile of the speaker and the second model is to intake the audio properties of a sample from a audio file corresponding to the speaker of the vocal profile.\n",
    "\n",
    "Once the training is completed, testing can be done on vocal profiles and audio files set aside.\n",
    "\n",
    "If the model can mostly reproduce the original audio file, then the all testing data will be used to train the model as well so the model can be better improved. The main purpose of this is the addition of vocal profiles to the model so the model might be able to learn more vocal profiles and might become be better at the main purpose of the project: replacing/transforming the user's voice to the speaker's voice.\n",
    "\n",
    "With the final model, the vocal profile will be either a customized creation or using a vocal profile from the speakers in the database. \n",
    "\n",
    "Note: Because the files with the audio properties are so large, the training will be done one file at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_directory = os.getcwd()\n",
    "\n",
    "# Creating Model directories:\n",
    "if os.path.exists(current_directory + '\\\\Vocal_Replace\\\\Model\\\\') != True:\n",
    "    os.mkdir(current_directory + '\\\\Vocal_Replace\\\\Model\\\\')\n",
    "    \n",
    "if os.path.exists(current_directory + '\\\\Vocal_Replace\\\\Model\\\\Saved_Models') != True:\n",
    "    os.mkdir(current_directory + '\\\\Vocal_Replace\\\\Model\\\\Saved_Models')\n",
    "    \n",
    "if os.path.exists(current_directory + '\\\\Vocal_Replace\\\\Model\\\\Model_Outputs') != True:\n",
    "    os.mkdir(current_directory + '\\\\Vocal_Replace\\\\Model\\\\Model_Outputs')\n",
    "    \n",
    "if os.path.exists(current_directory + '\\\\Vocal_Replace\\\\Model\\\\Trained_Speakers') != True:\n",
    "    os.mkdir(current_directory + '\\\\Vocal_Replace\\\\Model\\\\Trained_Speakers')\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the speakers DF which have speakers who's audio properties has been fully extracted:\n",
    "analyzed_speakers_df = pd.read_csv(current_directory + '\\\\Vocal_Replace\\\\Data\\\\Modified_Data\\\\Finished Speakers.csv')\n",
    "analyzed_speakers_list = list(analyzed_speakers_df['SPEAKER_ID'])\n",
    "\n",
    "# Loading the speakers DF to associate the gender to the speaker ID:\n",
    "speaker_df = pd.read_csv(current_directory + \"\\\\Vocal_Replace\\\\Data\\\\Modified_Data\\\\SPEAKER_Modified_Final.csv\")\n",
    "\n",
    "# Creating a DF of speaker_df that contains only the speaker IDs from analyzed_speakers_list:\n",
    "access_speakers_df = speaker_df[speaker_df.ID.isin(analyzed_speakers_list)]\n",
    "\n",
    "\n",
    "# Creating a DF of speakers that have been used to train the model and how many times the training has been \n",
    "# done on that speaker:\n",
    "if os.path.exists(current_directory \n",
    "                  + '\\\\Vocal_Replace\\\\Model\\\\Trained_Speakers\\\\Speakers - Model Training.csv') == True:\n",
    "    speakers_trained_df = pd.read_csv(current_directory \n",
    "                                      + '\\\\Vocal_Replace\\\\Model\\\\Trained_Speakers\\\\Speakers - Model Training.csv', \n",
    "                                      index_col= 0)\n",
    "    \n",
    "    # Updating the DF with speakers that have been newly extracted:\n",
    "    for speaker in analyzed_speakers_list:\n",
    "        if speaker in speakers_trained_df.SPEAKER_ID.values:\n",
    "            continue\n",
    "        \n",
    "        else:\n",
    "            add_row = pd.DataFrame({'SPEAKER_ID': speaker, 'AMOUNT_TRAINED': 0}, index = [len(speakers_trained_df)])\n",
    "            speakers_trained_df = pd.concat([speakers_trained_df, add_row], ignore_index= True)\n",
    "    \n",
    "else:\n",
    "    speakers_trained_df = pd.DataFrame({'SPEAKER_ID': analyzed_speakers_list, 'AMOUNT_TRAINED': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining custom metric:\n",
    "def custom_metric_mean(y_true, y_pred):\n",
    "    ## Want this to be as close to 0 as possible\n",
    "    return keras.backend.mean(y_true, axis=None, keepdims=False) - keras.backend.mean(y_pred, axis=None, keepdims=False)\n",
    "\n",
    "# Defining custom metric:\n",
    "def custom_metric_difference(y_true, y_pred):\n",
    "    ## Want this to be as close to 0 as possible\n",
    "    return keras.backend.sum(y_true, axis=None, keepdims=False) - keras.backend.sum(y_pred, axis=None, keepdims=False)\n",
    "    \n",
    "\n",
    "# Defining Model:\n",
    "def create_model():\n",
    "    ## Creating the TensorFlow model:\n",
    "    audio_X_train = keras.Input(shape= (69,), name= 'Audio_Properties_Input')\n",
    "    vocal_profile_individual = keras.Input(shape= (7,), name= 'Vocal_Profile_Input')\n",
    "\n",
    "    ## Audio Properties Model:\n",
    "    audio_model_input = keras.layers.Dense(69, activation= keras.layers.PReLU(input_shape=(69,)), kernel_initializer= 'RandomNormal')(audio_X_train)\n",
    "    audio_model_hidden_1 = keras.layers.Dense(900, activation= keras.layers.PReLU(), kernel_initializer= 'RandomNormal')(audio_model_input)\n",
    "    audio_model_hidden_2 = keras.layers.Dense(700, activation= keras.layers.PReLU(), kernel_initializer= 'RandomNormal')(audio_model_hidden_1)\n",
    "    audio_model_hidden_3 = keras.layers.Dense(500, activation= keras.layers.PReLU(), kernel_initializer= 'RandomNormal')(audio_model_hidden_2)\n",
    "    audio_model_hidden_4 = keras.layers.Dense(400, activation= keras.layers.PReLU(), kernel_initializer= 'RandomNormal')(audio_model_hidden_3)\n",
    "    audio_model_hidden_5 = keras.layers.Dense(300, activation= keras.layers.PReLU(), kernel_initializer= 'RandomNormal')(audio_model_hidden_4)\n",
    "    audio_model_hidden_6 = keras.layers.Dense(100, activation= keras.layers.PReLU(), kernel_initializer= 'RandomNormal')(audio_model_hidden_5)\n",
    "\n",
    "\n",
    "    ## Vocal Profile Model:\n",
    "    vocal_model_input = keras.layers.Dense(7, activation= keras.layers.PReLU(input_shape=(7,)), kernel_initializer= 'RandomNormal')(vocal_profile_individual)\n",
    "    vocal_model_hidden_1 = keras.layers.Dense(20, activation= keras.layers.PReLU(), kernel_initializer= 'RandomNormal')(vocal_model_input)\n",
    "    vocal_model_hidden_2 = keras.layers.Dense(100, activation= keras.layers.PReLU(), kernel_initializer= 'RandomNormal')(vocal_model_hidden_1)\n",
    "\n",
    "    ## Merging Audio Model + Vocal Model:\n",
    "    merged_model = keras.layers.concatenate([audio_model_hidden_6, vocal_model_hidden_2])\n",
    "    merged_model_hidden_1 = keras.layers.Dense(200, activation= keras.layers.PReLU(), kernel_initializer= 'RandomNormal')(merged_model)\n",
    "    merged_model_hidden_2 = keras.layers.Dense(200, activation= keras.layers.PReLU(), kernel_initializer= 'RandomNormal')(merged_model_hidden_1)\n",
    "    merged_model_hidden_3 = keras.layers.Dense(100, activation= keras.layers.PReLU(), kernel_initializer= 'RandomNormal')(merged_model_hidden_2)\n",
    "\n",
    "    ## Output Layer:\n",
    "    output_amplitude = keras.layers.Dense(1, activation= 'linear', kernel_initializer= 'RandomNormal', name= 'Output_Amplitude')(merged_model_hidden_3)\n",
    "\n",
    "    ## Molding the Model togther:\n",
    "    model = keras.Model(inputs= [audio_X_train, vocal_profile_individual], outputs= output_amplitude)\n",
    "\n",
    "    ## Compiling the Model:\n",
    "    model.compile(optimizer= keras.optimizers.Adam(learning_rate=0.001), loss= 'mean_squared_error', \n",
    "                  metrics= [custom_metric_mean, custom_metric_difference])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training using TensorFlow:\n",
    "\n",
    "# Loading in saved model (if it exists) or creating the model:\n",
    "# Because there is a custom metric defined, TensorFlow is unable to save/load custom metrics so the model will have to be\n",
    "# re-compiled after loading. The saved models seems to be intact as the model performance starts off better than a new model.\n",
    "# The HDF5 format is used to save the models due to the default & recommended SaveModel format being extremely unstable.\n",
    "if os.path.exists(current_directory + '\\\\Vocal_Replace\\\\Model\\\\Saved_Models\\\\Saved_Model_Full.h5') == True:\n",
    "    model_full_loaded = tf.keras.models.load_model(current_directory \n",
    "                                                   + '\\\\Vocal_Replace\\\\Model\\\\Saved_Models\\\\Saved_Model_Full.h5', \n",
    "                                                   custom_objects={\"custom_metric_mean\": custom_metric_mean, \n",
    "                                                                   'custom_metric_difference': custom_metric_difference,\n",
    "                                                                  'PReLU': keras.layers.PReLU()}, \n",
    "                                                   compile=False)\n",
    "    model_full_loaded.compile(optimizer= keras.optimizers.Adam(learning_rate=0.001), loss= 'mean_squared_error', \n",
    "                              metrics= [custom_metric_mean, custom_metric_difference])\n",
    "    \n",
    "else:\n",
    "    model_full_loaded = create_model()\n",
    "    \n",
    "    \n",
    "\n",
    "# Loading in the summary of vocal profiles:\n",
    "vocal_profile_df = pd.read_csv(current_directory \n",
    "                               + '\\\\Vocal_Replace\\\\Data\\\\Modified_Data\\\\Vocal_Profiles\\\\Vocal Profile Summary.csv', \n",
    "                               index_col=0)    \n",
    "\n",
    "# Converting gender into numeric (0, 1):\n",
    "for index, row in vocal_profile_df.iterrows():\n",
    "    if row.GENDER == 'M':\n",
    "        gender = 1\n",
    "        \n",
    "    else:\n",
    "        gender = 0\n",
    "        \n",
    "    vocal_profile_df.loc[index, 'GENDER'] = gender\n",
    "    \n",
    "vocal_profile_df = vocal_profile_df.astype({'GENDER': np.int64})\n",
    "\n",
    "\n",
    "# Accessing all anaylzed audio & training on batches & showing a progress bar:\n",
    "with tf.device('/GPU:0'):\n",
    "    for index, row in access_speakers_df.iterrows():\n",
    "        speaker_ID = row.ID\n",
    "\n",
    "        ## This is to prevent over-training on speakers that are trained early--allowing all speakers to be trained equally:\n",
    "        if speakers_trained_df.AMOUNT_TRAINED[speakers_trained_df.SPEAKER_ID == speaker_ID].values[0] <= np.average(speakers_trained_df.AMOUNT_TRAINED):\n",
    "            if row.SEX == 'M':\n",
    "                gender = 'Male'\n",
    "\n",
    "            else:\n",
    "                gender = 'Female'\n",
    "\n",
    "            ### Loading in the summary vocal profile of a speaker:\n",
    "            vocal_profile = vocal_profile_df[vocal_profile_df.SPEAKER_ID == speaker_ID]\n",
    "\n",
    "            ### Loading in the audio properties of a speaker:\n",
    "            filepath_audio_properties = (current_directory + '\\\\Vocal_Replace\\\\Data\\\\Modified_Data\\\\Audio_Properties\\\\' \n",
    "                                         + gender + '\\\\' + str(speaker_ID) + ' - Audio Properties.csv')\n",
    "\n",
    "            if os.path.exists(filepath_audio_properties) == True:\n",
    "                audio_properties_load = pd.read_csv(filepath_audio_properties, index_col= 0, chunksize=100000)\n",
    "\n",
    "                #### Training the model:\n",
    "                for audio_properties in audio_properties_load:\n",
    "                    label = audio_properties['AMPLITUDE']\n",
    "                    label = label.values\n",
    "\n",
    "                    audio_input = audio_properties.drop(['SPEAKER_ID', 'SPEAKER_GENDER', 'FILENAME', 'AMPLITUDE'], axis= 1)\n",
    "                    audio_input = audio_input.values\n",
    "\n",
    "                    extended_vocal_profile = pd.DataFrame({'SPEAKER_ID': vocal_profile.SPEAKER_ID.values[0], \n",
    "                                                           'GENDER': vocal_profile.GENDER.values[0], \n",
    "                                                           'MIN_RANGE': vocal_profile.MIN_RANGE.values[0], \n",
    "                                                           'MAX_RANGE': vocal_profile.MAX_RANGE.values[0], \n",
    "                                                           'AVERAGE_RANGE': vocal_profile.AVERAGE_RANGE.values[0],\n",
    "                                                           'STD_RANGE': vocal_profile.STD_RANGE.values[0], \n",
    "                                                           'MEDIAN_RANGE': vocal_profile.MEDIAN_RANGE.values[0]},\n",
    "                                                         index=range(len(audio_properties)))\n",
    "                    \n",
    "                    extended_vocal_profile = extended_vocal_profile.values\n",
    "                    \n",
    "                    print(speaker_ID)\n",
    "\n",
    "                    model_full_loaded.fit(x= [audio_input, extended_vocal_profile], \n",
    "                                          y= label, \n",
    "                                          epochs= 100,\n",
    "                                         batch_size= 4000)\n",
    "                    \n",
    "                    if gender == 'Male':\n",
    "                        print('Male', speaker_ID)\n",
    "                        \n",
    "                        model_male_loaded.fit(x= [audio_input, extended_vocal_profile], \n",
    "                                          y= label, \n",
    "                                          epochs= 100,\n",
    "                                         batch_size= 4000)\n",
    "                    \n",
    "                    else:\n",
    "                        print('Female', speaker_ID)\n",
    "                        \n",
    "                        model_female_loaded.fit(x= [audio_input, extended_vocal_profile], \n",
    "                                          y= label, \n",
    "                                          epochs= 100,\n",
    "                                         batch_size= 4000)\n",
    "\n",
    "                \n",
    "\n",
    "\n",
    "                ### Updating the number of times the speaker was used to train the model:\n",
    "                for index, row in speakers_trained_df.iterrows():\n",
    "                    if row.SPEAKER_ID == speaker_ID:\n",
    "                        speakers_trained_df.loc[index, 'AMOUNT_TRAINED'] += 100\n",
    "                        break\n",
    "                        \n",
    "            else:\n",
    "                print('Audio Properties File Not Present; Speaker: ', speaker_ID)\n",
    "                \n",
    "            # Exporting updated models and speakers trained:\n",
    "            speakers_trained_df.to_csv(current_directory + '\\\\Vocal_Replace\\\\Model\\\\Trained_Speakers\\\\Speakers - Model Training.csv')\n",
    "\n",
    "            model_full_loaded.save(current_directory + '\\\\Vocal_Replace\\\\Model\\\\Saved_Models\\\\Saved_Model_Full.h5', \n",
    "                                   overwrite= True, include_optimizer= True)\n",
    "                \n",
    "\n",
    "        else:\n",
    "            continue\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use if wanting to see the model diagram; this is a bit buggy so it might require installation of other packages:\n",
    "keras.utils.plot_model(model_full_loaded, 'multi_input_and_output_model.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
