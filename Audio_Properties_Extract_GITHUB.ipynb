{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, datetime\n",
    "\n",
    "from pyAudioAnalysis import audioBasicIO, ShortTermFeatures\n",
    "from pydub import AudioSegment\n",
    "\n",
    "import soundfile\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### !!!! IF STARTING HERE:<br>\n",
    "#### Move and unzip the datasets from http://www.openslr.org/12/ \n",
    "#### into the '\\\\Vocal_Replace\\\\Data\\\\Initial_Data' subdirectory!!!\n",
    "#### RENAME THE MAIN FOLDERS TO: \n",
    "#### LibriSpeech - dev-clean\n",
    "#### LibriSpeech - test-clean\n",
    "#### LibriSpeech - train-clean-100\n",
    "#### LibriSpeech - train-clean-360\n",
    "#### (Original naming scheme did not follow the scheme.) <br><br>\n",
    "\n",
    "##### The datasets used are: test-clean.tar.gz, train-clean-360.tar.gz, train-clean-100.tar.gz, and dev-clean.tar.gz\n",
    "##### Datasets were unzipped using 7-Zip (free-source software)\n",
    "##### Please read the README file from the databases as it informs how the files are named, ordered, \n",
    "##### the speaker associated, etc.<br><br>\n",
    "\n",
    "This script is to extract the audio properties from the audio recordings.\n",
    "\n",
    "CHAPTERS_Modified_Final.csv will serve as the guide for accessing into all directories and files.\n",
    "\n",
    "SoundFile is used to convert the FLAC audio files to WAV.\n",
    "\n",
    "pyAudioAnalysis is used as the extractor for audio properties. The audio properties extracted are:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading in CHAPTERS_Modified_Final.csv:\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "directory_reference = pd.read_csv(current_directory + \"\\\\Vocal_Replace\\\\Data\\\\Modified_Data\\\\CHAPTERS_Modified_Final.csv\")\n",
    "\n",
    "directory_reference.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading in the SPEAKER_Modified_Final.csv to obtain the gender for each speaker:\n",
    "speaker_df = pd.read_csv(current_directory + \"\\\\Vocal_Replace\\\\Data\\\\Modified_Data\\\\SPEAKER_Modified_Final.csv\")\n",
    "\n",
    "speaker_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating default filepath to access all audio databases:\n",
    "databases_directories = [('LibriSpeech - dev-clean', 'dev-clean'), \n",
    "                         ('LibriSpeech - test-clean', 'test-clean'), \n",
    "                         ('LibriSpeech - train-clean-100', 'train-clean-100'), \n",
    "                         ('LibriSpeech - train-clean-360', 'train-clean-360')]\n",
    "\n",
    "\n",
    "# Splitting and cleaning text files that reference the audio:\n",
    "for database_directory in databases_directories:\n",
    "    ## Creating a DF that only contains the SUBSET values that match the subdirectory = database_directory[1]\n",
    "    directory_select_df = directory_reference[directory_reference.SUBSET == database_directory[1]].copy()\n",
    "    \n",
    "    ### Accessing each subdirectory that contains the data files using directory_select_df\n",
    "    for index, row in directory_select_df.iterrows():\n",
    "        speaker_ID = row.READER\n",
    "        chapter_ID = row.ID\n",
    "        \n",
    "        directory_filepath = (current_directory + \"\\\\Data\\\\Initial_Data\\\\\" + database_directory[0] + \"\\\\\" \n",
    "                              + database_directory[1] + \"\\\\\" + str(speaker_ID) + \"\\\\\" + str(chapter_ID) + \"\\\\\")\n",
    "        \n",
    "        #### Creating a list of filenames:\n",
    "        file_list = os.listdir(directory_filepath)\n",
    "        \n",
    "        #### Creating a list of filenames without the file extensions (excluding the .txt file) and a variable assigned to\n",
    "        #### the .txt file (which includes the .txt file extension in the string):\n",
    "        filename_list = [filename.strip('.flac') for filename in file_list if '.flac' in filename]\n",
    "        \n",
    "        text_file = [filename for filename in file_list if '.txt' in filename][0]\n",
    "                \n",
    "        #### Creating a DF of the text associated with each filename:\n",
    "        with open(directory_filepath + text_file, 'r') as reader:\n",
    "            text_list = [reader.readline() for x in range(len(filename_list))]\n",
    "            \n",
    "        text_df = pd.DataFrame(columns= ['SPEAKER_CHAPTER_ORDER_ID', 'TEXT'], index= range(len(text_list)))\n",
    "        \n",
    "        counter = 0\n",
    "        \n",
    "        for text in text_list:\n",
    "            for filename in filename_list:\n",
    "                if filename in text:\n",
    "                    text = text.strip(filename + ' ').strip('\\n')\n",
    "                    \n",
    "                    text_df['SPEAKER_CHAPTER_ORDER_ID'].loc[counter] = filename\n",
    "                    text_df['TEXT'].loc[counter] = text\n",
    "                    \n",
    "                    counter += 1\n",
    "                    \n",
    "                    break\n",
    "                    \n",
    "        \n",
    "        #### Creating subdirectories in the Modifed_Data subdirectory to store text_df:\n",
    "        if os.path.exists(current_directory + '\\\\Vocal_Replace\\\\Data\\\\Modified_Data\\\\Text_And_Audio_Data\\\\') != True:\n",
    "            os.mkdir(current_directory + '\\\\Vocal_Replace\\\\Data\\\\Modified_Data\\\\Text_And_Audio_Data\\\\')\n",
    "        \n",
    "        if os.path.exists(current_directory + '\\\\Vocal_Replace\\\\Data\\\\Modified_Data\\\\Text_And_Audio_Data\\\\' + str(speaker_ID)) != True:\n",
    "            os.mkdir(current_directory + '\\\\Vocal_Replace\\\\Data\\\\Modified_Data\\\\Text_And_Audio_Data\\\\' + str(speaker_ID))\n",
    "        \n",
    "        if os.path.exists(current_directory + '\\\\Vocal_Replace\\\\Data\\\\Modified_Data\\\\Text_And_Audio_Data\\\\' + str(speaker_ID) + '\\\\' + \n",
    "                          str(chapter_ID)) != True:\n",
    "            os.mkdir(current_directory + '\\\\Vocal_Replace\\\\Data\\\\Modified_Data\\\\Text_And_Audio_Data\\\\' + str(speaker_ID) + '\\\\' + str(chapter_ID))\n",
    "        \n",
    "        text_df.to_csv(current_directory + '\\\\Vocal_Replace\\\\Data\\\\Modified_Data\\\\Text_And_Audio_Data\\\\' + str(speaker_ID) + '\\\\' + str(chapter_ID) \n",
    "                       + '\\\\' + str(speaker_ID) + '-' + str(chapter_ID) + ' - Text DataFrame.csv')\n",
    "        \n",
    "        \n",
    "        #### Creating audio DFs that contain the audio properties that will used as the input variables:\n",
    "        for file in file_list:\n",
    "            if '.flac' in file:\n",
    "                audio_filepath = directory_filepath + file\n",
    "                audio_time_series, sample_rate = librosa.load(audio_filepath)\n",
    "                \n",
    "                ###### Mel-scaled spectrogramâ€‹:\n",
    "                mel_spectrogram = librosa.feature.melspectrogram(y= audio_time_series, sr= sample_rate, n_mels= len(audio_time_series))\n",
    "                \n",
    "                ###### Pitch & magnitude:\n",
    "                pitches, magnitudes = librosa.piptrack(y=audio_time_series, sr=sample_rate, n_fft= len(audio_time_series), hop_length=len(audio_time_series))\n",
    "                \n",
    "                ###### Chroma:\n",
    "                chroma = librosa.feature.chroma_stft(y=audio_time_series, sr=sample_rate, n_chroma= len(audio_time_series), hop_length= len(audio_time_series))\n",
    "                \n",
    "                ###### Tempo (for entire audio):\n",
    "                tempo = librosa.beat.tempo(sr=sample_rate, y= audio_time_series)\n",
    "                \n",
    "                ###### Short-time Fourier Transformation:\n",
    "                short_time_fourier_transform = librosa.stft(y=audio_time_series, n_fft= len(audio_time_series), hop_length= len(audio_time_series))\n",
    "                \n",
    "                ###### Audio length/duration in seconds:\n",
    "                duration = librosa.get_duration(y= audio_time_series, sr= sample_rate)\n",
    "                \n",
    "                ###### Time = one sample per time slot/row:\n",
    "                time_list = []\n",
    "                for x in range(len(audio_time_series)):\n",
    "                    if x == 0:\n",
    "                        time = datetime.timedelta()\n",
    "                        time_list.append(time)\n",
    "                        time_increment = datetime.timedelta(seconds= duration/len(audio_time_series))\n",
    "\n",
    "                    else:\n",
    "                        time += time_increment\n",
    "                        time_list.append(time)\n",
    "                \n",
    "                \n",
    "                ###### Scaling/doubling the lists for pitches, magnitudes, and short_time_fourier_transform:\n",
    "                pitches_repeated = []\n",
    "                magnitudes_repeated = []\n",
    "                short_time_fourier_transform_repeated = []\n",
    "\n",
    "                for pitch in pitches:\n",
    "                    pitches_repeated.append(float(pitch))\n",
    "                    pitches_repeated.append(float(pitch))\n",
    "\n",
    "                for magnitude in magnitudes:\n",
    "                    magnitudes_repeated.append(float(magnitude))\n",
    "                    magnitudes_repeated.append(float(magnitude))\n",
    "\n",
    "                for fourier in short_time_fourier_transform:\n",
    "                    short_time_fourier_transform_repeated.append(fourier[0])\n",
    "                    short_time_fourier_transform_repeated.append(fourier[0])\n",
    "\n",
    "                if len(audio_time_series) % 2 != 0:\n",
    "                    pitches_repeated.pop(-1)\n",
    "                    magnitudes_repeated.pop(-1)\n",
    "                    short_time_fourier_transform_repeated.pop(-1)\n",
    "                    \n",
    "                    \n",
    "                ###### Obtaining the gender of the speaker:\n",
    "                gender = speaker_df[speaker_df['ID'] == speaker_ID].SEX.values[0]\n",
    "                \n",
    "                ###### Obtaining the text associated to the audio file:\n",
    "                text = text_df[text_df.SPEAKER_CHAPTER_ORDER_ID == file.strip('.flac')].TEXT.values[0]\n",
    "                    \n",
    "                    \n",
    "                ###### Combining all the audio properties, text, and speaker info into one DF:\n",
    "                combine_df = pd.DataFrame({'TIME': time_list, 'AUDIO_TIME_SERIES': audio_time_series, \n",
    "                                           'SAMPLE_RATE': sample_rate, 'MEL_SPECTROGRAM': list(mel_spectrogram), \n",
    "                                           'PITCH': pitches_repeated, 'MAGNITUDE': magnitudes_repeated, \n",
    "                                           'CHROMA': list(chroma), 'GLOBAL_TEMPO': float(tempo), \n",
    "                                           'DURATION_SEC': duration, 'SPEAKER': speaker_ID, \n",
    "                                           'GENDER': gender, 'TEXT': text})\n",
    "                "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
