{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## After running this cell, move and unzip the datasets from http://www.openslr.org/12/ \n",
    "########## into the '\\\\Vocal_Replace\\\\Data\\\\Initial_Data' subdirectory!!!\n",
    "########## RENAME THE MAIN FOLDERS TO: \n",
    "############### LibriSpeech - dev-clean\n",
    "############### LibriSpeech - test-clean\n",
    "############### LibriSpeech - train-clean-100\n",
    "############### LibriSpeech - train-clean-360\n",
    "######### Original naming scheme did not follow the scheme.\n",
    "\n",
    "##### The datasets used are: test-clean.tar.gz, train-clean-360.tar.gz, train-clean-100.tar.gz, and dev-clean.tar.gz\n",
    "##### Datasets were unzipped using 7-Zip (free-source software)\n",
    "##### Please read the README file from the databases as it informs how the files are named, ordered, \n",
    "##### the speaker associated, etc.\n",
    "\n",
    "\n",
    "# Creating/initializing all directories:\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "\n",
    "## Main Directory:\n",
    "if os.path.exists(current_directory + '\\\\Vocal_Replace') != True:\n",
    "    os.mkdir(current_directory + '\\\\Vocal_Replace')\n",
    "    \n",
    "\n",
    "### Creating Data Directory & Subdirectories:\n",
    "if os.path.exists(current_directory + '\\\\Vocal_Replace\\\\Data') != True:\n",
    "    os.mkdir(current_directory + '\\\\Vocal_Replace\\\\Data')\n",
    "\n",
    "if os.path.exists(current_directory + '\\\\Vocal_Replace\\\\Data\\\\Initial_Data') != True:\n",
    "    os.mkdir(current_directory + '\\\\Vocal_Replace\\\\Data\\\\Initial_Data')\n",
    "    #### Initial_Data will not be modified\n",
    "    \n",
    "if os.path.exists(current_directory + '\\\\Vocal_Replace\\\\Data\\\\Modified_Data') != True:\n",
    "    os.mkdir(current_directory + '\\\\Vocal_Replace\\\\Data\\\\Modified_Data')\n",
    "    #### Modified_Data will be all modifications to the Initial_Data; More subdirectories will be created later\n",
    "    \n",
    "\n",
    "### Creating Vocal Profiles Directory & Subdirectories:\n",
    "if os.path.exists(current_directory + '\\\\Vocal_Replace\\\\Vocal_Profiles') != True:\n",
    "    os.mkdir(current_directory + '\\\\Vocal_Replace\\\\Vocal_Profiles')\n",
    "    #### Vocal_Profiles will contain the extracted vocal signatures for each speaker\n",
    "    \n",
    "if os.path.exists(current_directory + '\\\\Vocal_Replace\\\\Vocal_Profiles\\\\Male') != True:\n",
    "    os.mkdir(current_directory + '\\\\Vocal_Replace\\\\Vocal_Profiles\\\\Male')\n",
    "    \n",
    "if os.path.exists(current_directory + '\\\\Vocal_Replace\\\\Vocal_Profiles\\\\Female') != True:\n",
    "    os.mkdir(current_directory + '\\\\Vocal_Replace\\\\Vocal_Profiles\\\\Female')\n",
    "    \n",
    "    \n",
    "### Creating User Vocal Data Directory & Subdirectories:\n",
    "if os.path.exists(current_directory + '\\\\Vocal_Replace\\\\User_Vocal_Data') != True:\n",
    "    os.mkdir(current_directory + '\\\\Vocal_Replace\\\\User_Vocal_Data')\n",
    "    #### All user data will be placed here\n",
    "    \n",
    "if os.path.exists(current_directory + '\\\\Vocal_Replace\\\\User_Vocal_Data\\\\Recordings') != True:\n",
    "    os.mkdir(current_directory + '\\\\Vocal_Replace\\\\User_Vocal_Data\\\\Recordings')\n",
    "    #### User vocal recordings\n",
    "    \n",
    "if os.path.exists(current_directory + '\\\\Vocal_Replace\\\\User_Vocal_Data\\\\Text') != True:\n",
    "    os.mkdir(current_directory + '\\\\Vocal_Replace\\\\User_Vocal_Data\\\\Text')\n",
    "    #### The text of the vocal recordings\n",
    "    \n",
    "if os.path.exists(current_directory + '\\\\Vocal_Replace\\\\User_Vocal_Data\\\\User_Transformation') != True:\n",
    "    os.mkdir(current_directory + '\\\\Vocal_Replace\\\\User_Vocal_Data\\\\User_Transformation')\n",
    "    #### Modifications to the recordings and text\n",
    "    \n",
    "if os.path.exists(current_directory + '\\\\Vocal_Replace\\\\User_Vocal_Data\\\\User_Final') != True:\n",
    "    os.mkdir(current_directory + '\\\\Vocal_Replace\\\\User_Vocal_Data\\\\User_Final')\n",
    "    #### Final data to be input into the model\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at one of the SPEAKER.txt file in any of the dataset folders (it is the same .txt file in all folders), it shows the speaker ID, gender of the speaker, which dataset they are featured in, the total time they have recorded in the dataset (in minutes), and the speaker's idenity. \n",
    "\n",
    "From this file, I want to extract and create a CSV file with the ID, gender, subset, and minutes. This file is separated by \"|\". Unfortunately, there is text in the beginning of the file and in the name column, there is one name with \"|\" in it and other names with parentheses or punctuations. This will make it harder to parse. \n",
    "\n",
    "However, since there is only a few names with these notations, the easy & simple way to start would be to manually copy-and-paste the table information I want out/delete the text in the beginning. Then, using Notepad++, I \"mark\"-ed/highlighted all \"|\" characters to examine which names contained this character (ID = 60 was the only speaker: |CBW|Simon --> CBW Simon). <br>\n",
    "This was repeated for: <br>\n",
    "\n",
    "Names with parentheses: <br>\n",
    "        Cynthia Lyons (1946-2011) --> Cynthia Lyons<br>\n",
    "        Alan Davis Drake (1945-2010) --> Alan Davis Drake<br><br>\n",
    "        Zale Schafer (Rose May Chamberlin Memorial Foundat --> Zale Schafer<br>\n",
    "        Nelly () --> Nelly<br>\n",
    "        icyjumbo (1964-2010) --> icyjumbo<br>\n",
    "        Gregg Margarite (1957-2012) --> Gregg Margarite<br>\n",
    "        Jacqueline (Jacqui) Grady --> Jacqueline Grady<br><br>\n",
    "    \n",
    "Names with commas: <br>\n",
    "    Cyril Law, Jr. --> Cyril Law<br>\n",
    "    Sandra in Wales, United Kingdom --> Sandra<br>\n",
    "    Carl Vonnoh, III --> Carl Vonnoh<br>\n",
    "    George Deprez, PhD --> George Deprez<br>\n",
    "    Priya, India --> Priya<br>\n",
    "    Pete Williams, Pittsburgh, PA --> Pete Williams<br>\n",
    "    Jamie Strassenburg, Cypress, California --> Jamie Strassenburg<br>\n",
    "    LaraC, Louisville, KY --> LaraC<br>\n",
    "    Lori Fuller Chugiak, AK --> Lori Fuller<br><br>\n",
    "\n",
    "Then using the find-and-replace tool in Notepad++, I replaced all \"|\" with commas to create a comma-separated txt.\n",
    "The txt file was saved as SPEAKER_Modified.txt in the \\Vocal_Replace\\Data\\Modified_Data subdirectory.<br><br>\n",
    "\n",
    "(I do not expect these datasets to be changed as it has been a few years since they were last modified according to the file properties.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading in SPEAKER_Modified.txt as a Pandas DataFrame:\n",
    "speaker_df = pd.read_csv(current_directory + \"\\\\Vocal_Replace\\\\Data\\\\Modified_Data\\\\SPEAKER_Modified.txt\")\n",
    "\n",
    "print(speaker_df.head(5))\n",
    "print(speaker_df.columns)\n",
    "print(speaker_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at the columns and values, there are whitespaces in every column.\n",
    "## Need to remove all irrelevant whitespaces:\n",
    "\n",
    "speaker_df_modified = pd.DataFrame(columns= ['ID', 'SEX', 'SUBSET', 'MINUTES', 'NAME'], index= range(0, len(speaker_df)))\n",
    "\n",
    "for index, row in speaker_df.iterrows():\n",
    "    speaker_df_modified['ID'].loc[index] = int(str(row['ID  ']).strip(' '))\n",
    "    speaker_df_modified['SEX'].loc[index] = row['SEX'].strip(' ')\n",
    "    speaker_df_modified['SUBSET'].loc[index] = row[' SUBSET           '].strip(' ')\n",
    "    speaker_df_modified['MINUTES'].loc[index] = float(str(row['MINUTES']).strip(' '))\n",
    "    speaker_df_modified['NAME'].loc[index] = row[' NAME'].strip(' ')\n",
    "    \n",
    "speaker_df_modified = speaker_df_modified.set_index('ID')\n",
    "    \n",
    "speaker_df_modified.to_csv(current_directory + \"\\\\Vocal_Replace\\\\Data\\\\Modified_Data\\\\SPEAKER_Modified_Final.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now repeating the same steps done on SPEAKER.txt but with CHAPTERS.txt\n",
    "\n",
    "The beginning text was removed and all commas were deleted using the find-and-replace tool in Notepad++.\n",
    "\n",
    "Then all \"|\" were replaced with commas.\n",
    "\n",
    "The txt file was saved as CHAPTERS_Modified.txt in the \\Vocal_Replace\\Data\\Modified_Data subdirectory.<br><br>\n",
    "\n",
    "\n",
    "Since the CHAPTER.txt contains all the information needed to access each and every audio recording and text associated with the audio recording, this will be the most used DataFrame (\\Vocal_Replace\\Data\\Modified_Data\\CHAPTERS_Modified_Final.txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading in CHAPTERS_Modified.txt as a Pandas DataFrame:\n",
    "chapters_df = pd.read_csv(current_directory + \"\\\\Vocal_Replace\\\\Data\\\\Modified_Data\\\\CHAPTERS_Modified.txt\")\n",
    "\n",
    "print(chapters_df.head(5))\n",
    "print(chapters_df.columns)\n",
    "print(chapters_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at the columns and values, there are whitespaces in every column.\n",
    "# The book title and chapter titles were not taken since they are not important in the overall scope.\n",
    "## Need to remove all irrelevant whitespaces:\n",
    "\n",
    "chapters_df_modified = pd.DataFrame(columns= ['ID', 'READER', 'MINUTES', 'SUBSET', 'PROJECT', 'BOOK_ID', \n",
    "                                              ], index= range(0, len(chapters_df)))\n",
    "\n",
    "for index, row in chapters_df.iterrows():  \n",
    "    chapters_df_modified['ID'].loc[index] = int(str(row['ID    ']).strip(' '))\n",
    "    chapters_df_modified['READER'].loc[index] = int(str(row['READER']).strip(' '))\n",
    "    chapters_df_modified['MINUTES'].loc[index] = float(str(row['MINUTES']).strip(' '))\n",
    "    chapters_df_modified['SUBSET'].loc[index] = row[' SUBSET           '].strip(' ')\n",
    "    chapters_df_modified['PROJECT'].loc[index] = int(str(row[' PROJ.']).strip(' '))\n",
    "    chapters_df_modified['BOOK_ID'].loc[index] = int(str(row['BOOK ID']).strip(' '))\n",
    "    \n",
    "chapters_df_modified = chapters_df_modified.set_index('READER').sort_index()\n",
    "    \n",
    "chapters_df_modified.to_csv(current_directory + \"\\\\Vocal_Replace\\\\Data\\\\Modified_Data\\\\CHAPTERS_Modified_Final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
